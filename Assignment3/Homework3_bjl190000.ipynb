{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HLT Assignment 3: WordNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WordNet is a module in the NLTK library which allows programmers to access information about a given word such as all the definitions and synonyms of a word. It also organizes words into a hierarchy which can be traversed to see how words are related to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.wsd import lesk\n",
    "from nltk.book import *\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synsets: \n",
      " [Synset('fish.n.01'), Synset('fish.n.02'), Synset('pisces.n.02'), Synset('pisces.n.01'), Synset('fish.v.01'), Synset('fish.v.02')]\n"
     ]
    }
   ],
   "source": [
    "noun = \"fish\"\n",
    "word_synsets = wn.synsets(noun)\n",
    "print(\"Synsets: \\n\", word_synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "any of various mostly cold-blooded aquatic vertebrates usually having scales and breathing through gills\n"
     ]
    }
   ],
   "source": [
    "synset_sample = word_synsets[0]\n",
    "synset_sample_name = synset_sample.name()\n",
    "print(wn.synset(synset_sample_name).definition())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traversal up the Noun Hierarchy\n",
    "WordNet's nouns have a tall and well-connected hierarchy. Especially because I chose a biological word, which has hierarchical nouns to describe life anyways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('aquatic_vertebrate.n.01')\n",
      "Synset('vertebrate.n.01')\n",
      "Synset('chordate.n.01')\n",
      "Synset('animal.n.01')\n",
      "Synset('organism.n.01')\n",
      "Synset('living_thing.n.01')\n",
      "Synset('whole.n.02')\n",
      "Synset('object.n.01')\n",
      "Synset('physical_entity.n.01')\n",
      "Synset('entity.n.01')\n"
     ]
    }
   ],
   "source": [
    "hypernym = synset_sample.hypernyms()[0]\n",
    "top = wn.synset('entity.n.01')\n",
    "while hypernym:\n",
    "   print(hypernym)\n",
    "   if hypernym == top:\n",
    "      break\n",
    "   if hypernym.hypernyms():\n",
    "      hypernym = hypernym.hypernyms()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypernyms:\n",
      " [Synset('aquatic_vertebrate.n.01')]\n",
      "Hyponyms:\n",
      " [Synset('bony_fish.n.01'), Synset('bottom-feeder.n.02'), Synset('bottom_lurkers.n.01'), Synset('cartilaginous_fish.n.01'), Synset('climbing_perch.n.01'), Synset('fingerling.n.01'), Synset('food_fish.n.01'), Synset('game_fish.n.01'), Synset('mouthbreeder.n.01'), Synset('northern_snakehead.n.01'), Synset('rough_fish.n.01'), Synset('spawner.n.01'), Synset('young_fish.n.01')]\n",
      "Meronyms:\n",
      " [Synset('fin.n.06'), Synset('fish_scale.n.01'), Synset('fishbone.n.01'), Synset('lateral_line.n.01'), Synset('milt.n.02'), Synset('roe.n.02'), Synset('tail_fin.n.03')]\n",
      "Holonyms:\n",
      " []\n",
      "Antonyms:\n",
      " []\n"
     ]
    }
   ],
   "source": [
    "print(\"Hypernyms:\\n\",synset_sample.hypernyms())\n",
    "print(\"Hyponyms:\\n\", synset_sample.hyponyms())\n",
    "print(\"Meronyms:\\n\",synset_sample.part_meronyms())\n",
    "print(\"Holonyms:\\n\", synset_sample.part_holonyms())\n",
    "print(\"Antonyms:\\n\", synset_sample.lemmas()[0].antonyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('analyze.v.01'), Synset('examine.v.02'), Synset('probe.v.01'), Synset('examine.v.04'), Synset('test.v.01')]\n"
     ]
    }
   ],
   "source": [
    "verb = \"examine\"\n",
    "verb_synsets = wn.synsets(verb)\n",
    "print(verb_synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definition:\n",
      " question or examine thoroughly and closely\n",
      "Examples:\n",
      " []\n",
      "Lemmas:\n",
      " [Lemma('probe.v.01.probe'), Lemma('probe.v.01.examine')]\n"
     ]
    }
   ],
   "source": [
    "verb_synset_sample = verb_synsets[2]\n",
    "verb_synset_name = verb_synset_sample.name()\n",
    "print(\"Definition:\\n\", wn.synset(verb_synset_name).definition())\n",
    "print(\"Examples:\\n\", wn.synset(verb_synset_name).examples())\n",
    "print(\"Lemmas:\\n\", wn.synset(verb_synset_name).lemmas())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verb Traversal\n",
    "The verb hierarchy seems to be very flat and divided. It does not have a top level synset unlike the noun hierarchy. This is likely because verbs cannot be connected easily using synonyms. For example, look and run are both bodily movements, but there's no verb to describe the movement of a body part. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traversal:\n",
      "Synset('investigate.v.01') Synset('analyze.v.01')\n",
      "Synset('analyze.v.01') Synset('analyze.v.01')\n"
     ]
    }
   ],
   "source": [
    "print(\"Traversal:\")\n",
    "hypernym = verb_synset_sample.hypernyms()[0]\n",
    "previous_hypernym = wn.synset('analyze.v.01')\n",
    "while hypernym:\n",
    "   print(hypernym, previous_hypernym)\n",
    "   if hypernym == previous_hypernym:\n",
    "      break\n",
    "   if hypernym.hypernyms():\n",
    "      hypernym = hypernym.hypernyms()[0]\n",
    "\n",
    "   previous_hypernym = hypernym"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examine\n",
      "examine\n"
     ]
    }
   ],
   "source": [
    "#show all forms of the verb\n",
    "print(wn.morphy(\"examining\", wn.VERB))\n",
    "print(wn.morphy(\"examined\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mouse = wn.synset(\"mouse.n.01\")\n",
    "hamster = wn.synset(\"hamster.n.01\")\n",
    "wn.path_similarity(mouse, hamster)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesk Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('bottle.n.01') a glass or plastic vessel used for storing drinks or other liquids; typically cylindrical without handles and with a narrow neck that can be plugged or capped\n",
      "Synset('bottle.n.02') the quantity contained in a bottle\n",
      "Synset('bottle.n.03') a vessel fitted with a flexible teat and filled with milk or formula; used as a substitute for breast feeding infants and very young children\n",
      "Synset('bottle.v.01') store (liquids or gases) in bottles\n",
      "Synset('bottle.v.02') put into bottles\n"
     ]
    }
   ],
   "source": [
    "lesk_word = \"bottle\"\n",
    "\n",
    "for ss in wn.synsets(lesk_word):\n",
    "   print(ss, ss.definition())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('bottle.n.03')\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"I want to bottle the water in that lake.\"\n",
    "\n",
    "print(lesk(test_sentence, lesk_word))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SentiWordNet\n",
    "SentiWordNet is a modification of WordNet, which adds sentiment scores to each word reflecting how positive or negative the word usually is depending on the definition.\n",
    "\n",
    "The scores given are fairly accurate and there are some synsets where the word has both a positive and a negative score. For example, \"fury\" can be be used positively like \"I worked myself up into a fury\". SentiWordNet seems to struggle with modifiers like 'not' or 'never'. It should modify the word after it to be the opposite, but since SWN is just for tokens, it just assigns them as negative.\n",
    "\n",
    "While knowing the strength of how positive/negative any word is is useful, it clearly requires a good model to utilize it. For example, if you were to simply add all the scores of the example sentence below, you would get a negative score. However, the 'not' in the sentence makes the sentence neutral at worst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<very.s.01: PosScore=0.5 NegScore=0.0> ObjScore: 0.5\n",
      "<identical.s.02: PosScore=0.5 NegScore=0.125> ObjScore: 0.375\n",
      "<very.r.01: PosScore=0.25 NegScore=0.25> ObjScore: 0.5\n",
      "<very.r.02: PosScore=0.25 NegScore=0.0> ObjScore: 0.75\n"
     ]
    }
   ],
   "source": [
    "emotional_word = \"very\"\n",
    "emot_word_list = swn.senti_synsets(emotional_word)\n",
    "for ss in emot_word_list:\n",
    "   print(ss, \"ObjScore:\", ss.obj_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['His', 'question', 'was', 'not', 'terribly', 'bad.']\n",
      "<question.n.01: PosScore=0.125 NegScore=0.25>\n",
      "<washington.n.02: PosScore=0.0 NegScore=0.0>\n",
      "<not.r.01: PosScore=0.0 NegScore=0.625>\n",
      "<terribly.r.01: PosScore=0.25 NegScore=0.0>\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"His question was not terribly bad.\"\n",
    "\n",
    "print(test_sentence.split())\n",
    "for token in test_sentence.split():\n",
    "   syn_list = list(swn.senti_synsets(token))\n",
    "   if (syn_list):\n",
    "      syn = syn_list[0]\n",
    "      print(syn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocations\n",
    "Collocations are sequences of words which are frequently used together and have greater rhetorical effect. They usually occur because they sounds more natural to native speakers. The below code finds collocations in U.S. Inaugural Addresses and finds the Point-Wise Mutual Information (PMI) to find how strong the association between the two words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; fellow citizens; years ago; four years; Federal\n",
      "Government; General Government; American people; Vice President; God\n",
      "bless; Chief Justice; one another; fellow Americans; Old World;\n",
      "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
      "tribes; public debt; foreign nations\n"
     ]
    }
   ],
   "source": [
    "text4.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fellow - Citizens of the Senate and of the House o\n",
      "10025\n",
      "Word 'United' probability: 0.017\n",
      "Word 'States' probability: 0.033\n",
      "Collocation 'United States' probability: 0.016\n",
      "4.815657649820885\n"
     ]
    }
   ],
   "source": [
    "text = \" \".join(text4.tokens)\n",
    "print(text[:50])\n",
    "\n",
    "num_words = len(set(text4.tokens))\n",
    "print(num_words)\n",
    "\n",
    "def find_pmi(text, num_words, word1, word2):\n",
    "    word1_prob = text.count(word1)/num_words\n",
    "    word2_prob = text.count(word2)/num_words\n",
    "    both_words = word1 + \" \" + word2\n",
    "    both_words_prob =  text.count(both_words)/num_words\n",
    "\n",
    "    print(\"Word '%s' probability: %.3f\" % (word1, word1_prob)) \n",
    "    print(\"Word '%s' probability: %.3f\" % (word2, word2_prob)) \n",
    "    print(\"Collocation '%s' probability: %.3f\" % (both_words, both_words_prob)) \n",
    "\n",
    "    pmi = math.log2(both_words_prob/(word1_prob * word2_prob))\n",
    "    return pmi\n",
    "\n",
    "pmi = find_pmi(text, num_words, \"United\", \"States\")\n",
    "print(pmi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc7c0481baace6a597cdc1b9f0de4445b935b38d9af22f80f4ce81dfadb25b97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
